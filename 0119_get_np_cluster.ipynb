{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3629, 19)\n",
      "(3583, 28)\n"
     ]
    }
   ],
   "source": [
    "path_text = './data/data_regression.xlsx'\n",
    "path_series = './data/data_time_series_feature_select_pro.xlsx'\n",
    "df_text = pd.read_excel(path_text)\n",
    "df_series = pd.read_excel(path_series)\n",
    "print(df_text.shape)\n",
    "print(df_series.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载word2vec模型\n",
    "wv_model_CHI = Word2Vec.load('./word2vec_model/wv_model_CHI.model')\n",
    "wv_model_IG = Word2Vec.load('./word2vec_model/wv_model_IG.model')\n",
    "wv_model_MI = Word2Vec.load('./word2vec_model/wv_model_MI.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载tf_idf模型\n",
    "TF_IDF = np.load('./tf_idf/tf_idf.npy',allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 病区编码\n",
    "coder = {\n",
    "    '口腔科病区':1,\n",
    "    '妇产科病区':2,\n",
    "    '心血管病区':3,\n",
    "    '整形外科病区':4,\n",
    "    '普通外科病区':5,\n",
    "    '普通胸外科病区':6,\n",
    "    '泌尿外科中心病区':7,\n",
    "    '眼科病区':8,\n",
    "    '神经内科病区':9,\n",
    "    '神经外科病区':10,\n",
    "    '耳鼻咽喉科病区':11,\n",
    "    '肝胆外科病区':12,\n",
    "    '骨科病区':13\n",
    "}\n",
    "\n",
    "def code_department(s,coder):\n",
    "    return coder[s]\n",
    "\n",
    "# 根据某一种特征选择方法 处理文本df\n",
    "def handle_text(df_text,feature_method):\n",
    "    df = df_text.filter(['手术ID','性别','年龄','体重','身高','病区','实施手术_'+feature_method,'术前诊断_'+feature_method]).copy()\n",
    "    print('输入的文本df:{}'.format(df.shape))\n",
    "    # 去除空值\n",
    "    df.dropna(how='all',subset=['实施手术_'+feature_method,'术前诊断_'+feature_method],inplace=True)\n",
    "    df.fillna(value='',inplace=True)\n",
    "    # 处理一些数据\n",
    "    df['文本_'+feature_method] = df['实施手术_'+feature_method] + '|' + df['术前诊断_'+feature_method]\n",
    "    df['BMI'] = df['体重'] / (df['身高'] / 100) ** 2\n",
    "    dummies_sex = pd.get_dummies(df['性别'],prefix='sex')\n",
    "    df = pd.concat([df,dummies_sex],axis=1)\n",
    "    df['病区'] = df['病区'].apply(code_department,args=(coder,))\n",
    "    # 去除不需要的行\n",
    "    df.drop(['实施手术_'+feature_method,'术前诊断_'+feature_method,'体重','身高','性别'],axis=1,inplace=True)\n",
    "    print('删除后的文本df:{}'.format(df.shape))\n",
    "    return df\n",
    "\n",
    "# 根据是否进行插值,处理时间序列的df\n",
    "def handle_series(df_series,isInterpolation):\n",
    "    cols = ['手术ID']\n",
    "    if isInterpolation: #进行了插值处理\n",
    "        cols.extend(['NBPDIA_inter_feature','NBPSYS_inter_feature','PR_inter_feature','SPO2_inter_feature'])\n",
    "    else:\n",
    "        cols.extend(['NBPDIA_feature','NBPSYS_feature','PR_feature','SPO2_feature'])\n",
    "    df = df_series.filter(cols).copy()\n",
    "    print('处理后的时间序列df:{}'.format(df.shape))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# 生成numpy特征矩阵\n",
    "def generate_np(handled_text,handled_series):\n",
    "    print('handled_text:{}'.format(handled_text.shape))\n",
    "    print('handled_series:{}'.format(handled_series.shape))\n",
    "    df = pd.merge(handled_text,handled_series,on='手术ID',how='inner')\n",
    "    print('合并后:{}'.format(df.shape))\n",
    "    # 结构化特征\n",
    "    np_strud = df.filter(['年龄','BMI','sex_男','sex_女']).values\n",
    "    print('np_strud:{}'.format(np_strud.shape))\n",
    "    # 文本特征\n",
    "    np_text = np.array([])\n",
    "    feature_method = df.columns[3].split('_')[1]\n",
    "    wv_model = None\n",
    "    if feature_method == 'CHI':\n",
    "        wv_model = wv_model_CHI\n",
    "    if feature_method == 'IG':\n",
    "        wv_model = wv_model_IG\n",
    "    if feature_method == 'MI':\n",
    "        wv_model = wv_model_MI\n",
    "    operation_ids = list(df['手术ID'])\n",
    "    for text,operation_id in zip(df['文本_'+feature_method],operation_ids):\n",
    "        tmp = np.zeros(50)\n",
    "        for w in text.split('|'):\n",
    "            if w != '':\n",
    "                tmp = tmp + TF_IDF[operation_id][w] * wv_model[w]\n",
    "        if np_text.shape[0] == 0:\n",
    "            np_text = tmp\n",
    "        else:\n",
    "            np_text = np.vstack((np_text,tmp))\n",
    "    print('np_text:{}'.format(np_text.shape))\n",
    "    # 时间序列特征\n",
    "    series_val = [] \n",
    "    is_inter = 'inter' in df.columns[-1]\n",
    "    cols = None\n",
    "    df_series = None\n",
    "    if is_inter:\n",
    "        df_series = df['NBPDIA_inter_feature']+' '+df['NBPSYS_inter_feature']+' '+df['PR_inter_feature']+' '+df['SPO2_inter_feature']\n",
    "    else:\n",
    "        df_series = df['NBPDIA_feature']+' '+df['NBPSYS_feature']+' '+df['PR_feature']+' '+df['SPO2_feature']\n",
    "    df_series.apply(lambda s:series_val.append([float(c) for c in s.split(' ')]))\n",
    "    np_series = np.array(series_val)\n",
    "    print('np_series:{}'.format(np_series.shape))\n",
    "    # 病区特征\n",
    "    np_y = df['病区'].values.reshape(-1,1)\n",
    "    print('np_y:{}'.format(np_y.shape))\n",
    "    # 合并\n",
    "    return np.hstack((np_strud,np_text,np_series,np_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入的文本df:(3629, 8)\n",
      "删除后的文本df:(3629, 7)\n",
      "处理后的时间序列df:(3583, 5)\n",
      "handled_text:(3629, 7)\n",
      "handled_series:(3583, 5)\n",
      "合并后:(3583, 11)\n",
      "np_strud:(3583, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\Anaconda3\\envs\\dataAnalysis\\lib\\site-packages\\ipykernel_launcher.py:25: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np_text:(3583, 50)\n",
      "np_series:(3583, 40)\n",
      "np_y:(3583, 1)\n",
      "处理后的时间序列df:(3583, 5)\n",
      "handled_text:(3629, 7)\n",
      "handled_series:(3583, 5)\n",
      "合并后:(3583, 11)\n",
      "np_strud:(3583, 4)\n",
      "np_text:(3583, 50)\n",
      "np_series:(3583, 40)\n",
      "np_y:(3583, 1)\n",
      "输入的文本df:(3629, 8)\n",
      "删除后的文本df:(3629, 7)\n",
      "处理后的时间序列df:(3583, 5)\n",
      "handled_text:(3629, 7)\n",
      "handled_series:(3583, 5)\n",
      "合并后:(3583, 11)\n",
      "np_strud:(3583, 4)\n",
      "np_text:(3583, 50)\n",
      "np_series:(3583, 40)\n",
      "np_y:(3583, 1)\n",
      "处理后的时间序列df:(3583, 5)\n",
      "handled_text:(3629, 7)\n",
      "handled_series:(3583, 5)\n",
      "合并后:(3583, 11)\n",
      "np_strud:(3583, 4)\n",
      "np_text:(3583, 50)\n",
      "np_series:(3583, 40)\n",
      "np_y:(3583, 1)\n",
      "输入的文本df:(3629, 8)\n",
      "删除后的文本df:(3245, 7)\n",
      "处理后的时间序列df:(3583, 5)\n",
      "handled_text:(3245, 7)\n",
      "handled_series:(3583, 5)\n",
      "合并后:(3205, 11)\n",
      "np_strud:(3205, 4)\n",
      "np_text:(3205, 50)\n",
      "np_series:(3205, 40)\n",
      "np_y:(3205, 1)\n",
      "处理后的时间序列df:(3583, 5)\n",
      "handled_text:(3245, 7)\n",
      "handled_series:(3583, 5)\n",
      "合并后:(3205, 11)\n",
      "np_strud:(3205, 4)\n",
      "np_text:(3205, 50)\n",
      "np_series:(3205, 40)\n",
      "np_y:(3205, 1)\n"
     ]
    }
   ],
   "source": [
    "feature_methods = ['CHI','IG','MI']\n",
    "for feature_method in feature_methods:\n",
    "    handled_text = handle_text(df_text,feature_method)\n",
    "    for is_inter in [True,False]:\n",
    "        handled_series = handle_series(df_series,is_inter)\n",
    "        np_data = generate_np(handled_text,handled_series)\n",
    "        np.save('./np_cluster_pro/np_{}_{}.npy'.format(feature_method,str(is_inter)),np_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_t = np.load('./np_cluster_pro/np_CHI_False.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[36.        , 25.1486054 ,  0.        ,  1.        ],\n",
       "       [51.        , 22.65625   ,  0.        ,  1.        ],\n",
       "       [66.        , 22.50930904,  0.        ,  1.        ],\n",
       "       ...,\n",
       "       [34.        , 24.00548697,  0.        ,  1.        ],\n",
       "       [29.        , 25.5588462 ,  0.        ,  1.        ],\n",
       "       [29.        , 30.078125  ,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_t[:,0:4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -3.91540924,   6.39076814, -10.60575433, ...,  -4.85250763,\n",
       "         28.59868014,  -5.80400626],\n",
       "       [ 20.98289454,  -6.42012958, -17.16561925, ...,   8.91219554,\n",
       "          5.16832945,  -2.20582636],\n",
       "       [ 32.52614024, -14.33920735, -15.76525956, ...,  17.23539725,\n",
       "         20.7365731 ,   2.14595723],\n",
       "       ...,\n",
       "       [  3.81526968,  -8.26959085, -11.96560616, ...,  16.00285518,\n",
       "         -5.36332175, -25.96547931],\n",
       "       [ -7.22212793,   3.02416834, -10.03417998, ...,  -8.85705045,\n",
       "         24.24621312, -15.96307817],\n",
       "       [ -1.86003169,  11.37191236, -13.89927968, ..., -10.20666629,\n",
       "         29.40385485,  -9.20128256]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_t[:,4:54]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 3.,  4.,  3., ...,  3.,  4.,  4.],\n",
       "       [ 0.,  0.,  2., ...,  0.,  0.,  2.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [20., 14., 17., ...,  1.,  0.,  4.],\n",
       "       [24.,  8., 11., ..., 14., 11., 26.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_t[:,54:94]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dataAnalysis]",
   "language": "python",
   "name": "conda-env-dataAnalysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
